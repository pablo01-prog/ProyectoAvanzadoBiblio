import streamlit as st
import joblib
import os
import re
import easyocr
import numpy as np
import whisper # Reemplazamos speech_recognition por Whisper
import tempfile # Necesario para procesar el audio temporalmente
from PIL import Image
from dotenv import load_dotenv
import google.generativeai as genai

# --- 1. CONFIGURACI√ìN DE SEGURIDAD Y RECURSOS ---
# Cargamos las variables de entorno (tu API key de Gemini)
load_dotenv()
api_key = os.getenv("API_KEY")

# Validaci√≥n de seguridad: detener la app si no hay clave
if not api_key:
    st.error("Error: No se encontr√≥ la API_KEY en el archivo .env")
    st.stop()

# Configuraci√≥n de Gemini
genai.configure(api_key=api_key)
model_gemini = genai.GenerativeModel('gemini-1.5-flash-latest')

# Usamos st.cache_resource para cargar los modelos pesados solo una vez.
# Esto evita que Streamlit los recargue cada vez que el usuario hace un clic.
@st.cache_resource
def cargar_recursos():
    # 1. Cargar el modelo de Machine Learning (Scikit-Learn)
    try:
        modelo_ml = joblib.load('modelo_libros.pkl')
    except Exception as e:
        modelo_ml = None
        
    # 2. Cargar el modelo OCR (EasyOCR)
    lector_ocr = easyocr.Reader(['es'], gpu=False) 
    
    # 3. Cargar el modelo de Transcripci√≥n (Whisper - Modelo 'base' para que sea r√°pido)
    modelo_audio = whisper.load_model("base")
    
    return modelo_ml, lector_ocr, modelo_audio

# Instanciamos los recursos
modelo_local, reader, whisper_model = cargar_recursos()

# Advertencia si falta el modelo local
if modelo_local is None:
    st.warning("‚ö†Ô∏è No se pudo cargar 'modelo_libros.pkl'. Aseg√∫rate de subirlo a tu repositorio de GitHub.")

# --- 2. FUNCIONES DE APOYO ---
def es_entrada_valida(texto):
    """Valida que el texto no est√© vac√≠o y contenga letras para evitar errores en la API."""
    if not texto or len(texto.strip()) < 3:
        return False, "La entrada es demasiado corta. Escribe un poco m√°s."
    if not re.search(r'[a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë]', texto):
        return False, "Entrada no v√°lida: Por favor usa palabras, no solo n√∫meros o s√≠mbolos."
    return True, ""

def procesar_solicitud(texto_entrada):
    """Clasifica el texto con el modelo local y genera recomendaciones con Gemini."""
    valido, mensaje_error = es_entrada_valida(texto_entrada)
    if not valido:
        return None, mensaje_error
    
    # 1. Clasificaci√≥n local (ML)
    categoria = "Desconocido"
    if modelo_local is not None:
        try:
            categoria = modelo_local.predict([texto_entrada])[0]
        except Exception as e:
            categoria = "Error en predicci√≥n"

    # 2. Generaci√≥n con Gemini
    prompt = (
        f"El usuario busca libros basados en esta descripci√≥n: '{texto_entrada}'. "
        f"El sistema de Machine Learning ha detectado el g√©nero: {categoria}. "
        f"Act√∫a como un bibliotecario experto y recomienda 3 libros espec√≠ficos (con autor) "
        f"que encajen perfectamente. Incluye una breve y atractiva frase de por qu√© leer cada uno."
    )
    
    try:
        response = model_gemini.generate_content(prompt)
        if response and response.text:
            return categoria, response.text
        else:
            return categoria, "Gemini no devolvi√≥ una respuesta v√°lida."
    except Exception as e:
        return categoria, f"Error al conectar con Gemini: {str(e)}"

# --- 3. INTERFAZ DE USUARIO (STREAMLIT) ---
st.set_page_config(page_title="Biblioteca Inteligente", page_icon="üìö", layout="centered")
st.title("üìö Mi Biblioteca Virtual Inteligente")
st.markdown("Clasificaci√≥n mediante **Machine Learning local**, OCR, Whisper y recomendaciones de **Gemini 1.5 Flash**.")
st.markdown("---")

# Creaci√≥n de pesta√±as para las distintas funcionalidades
tab_txt, tab_img, tab_aud = st.tabs(["‚úçÔ∏è Texto", "üì∑ Imagen (OCR)", "üéôÔ∏è Audio (Whisper)"])

# --- PESTA√ëA 1: TEXTO ---
with tab_txt:
    st.subheader("B√∫squeda por descripci√≥n")
    user_input = st.text_area("¬øQu√© te apetece leer hoy?", placeholder="Ej: Me gustan las historias de cr√≠menes en la √©poca victoriana...")
    
    if st.button("Analizar y Recomendar", key="btn_texto"):
        with st.spinner("Analizando tu petici√≥n..."):
            cat, resultado = procesar_solicitud(user_input)
            if cat:
                st.success(f"üé≠ G√©nero detectado por el modelo: **{cat}**")
                st.markdown(resultado)
            else:
                st.warning(resultado)

# --- PESTA√ëA 2: IMAGEN (OCR) ---
with tab_img:
    st.subheader("Extraer texto de una contraportada o sinopsis")
    archivo_img = st.file_uploader("Sube una foto", type=['jpg', 'jpeg', 'png'])
    
    if archivo_img:
        # Mostrar la imagen
        img_pil = Image.open(archivo_img)
        st.image(img_pil, caption="Imagen cargada", use_container_width=True)
        # Convertir a numpy array para EasyOCR
        img_array = np.array(img_pil) 
        
        if st.button("Escanear Imagen y Recomendar", key="btn_img"):
            with st.spinner("Leyendo texto de la imagen..."):
                try:
                    # detail=0 devuelve solo una lista de textos
                    resultado_ocr = reader.readtext(img_array, detail=0)
                    texto_extraido = " ".join(resultado_ocr)
                    
                    if texto_extraido.strip():
                        st.info(f"**Texto detectado:** {texto_extraido}")
                        cat, resultado = procesar_solicitud(texto_extraido)
                        if cat:
                            st.success(f"üé≠ G√©nero detectado: **{cat}**")
                            st.markdown(resultado)
                    else:
                        st.error("No se detect√≥ texto legible en la imagen.")
                except Exception as e:
                    st.error(f"Error en el procesamiento OCR: {e}")

# --- PESTA√ëA 3: AUDIO (WHISPER) ---
with tab_aud:
    st.subheader("Recomendaci√≥n por voz")
    archivo_audio = st.file_uploader("Sube un archivo de audio (.wav, .mp3)", type=['wav', 'mp3', 'm4a'])
    
    if archivo_audio:
        st.audio(archivo_audio)
        if st.button("Transcribir y Analizar", key="btn_aud"):
            with st.spinner("Transcribiendo el audio con Whisper..."):
                # Whisper requiere un archivo f√≠sico en disco, as√≠ que creamos uno temporal
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_audio:
                    tmp_audio.write(archivo_audio.read())
                    tmp_audio_path = tmp_audio.name
                
                try:
                    # Transcribir usando el modelo cargado en cach√©
                    resultado_whisper = whisper_model.transcribe(tmp_audio_path, language="es")
                    texto_voz = resultado_whisper["text"]
                    
                    st.info(f"**Transcripci√≥n:** {texto_voz}")
                    
                    # Pasar el texto transcrito al pipeline de ML + Gemini
                    cat, resultado = procesar_solicitud(texto_voz)
                    if cat:
                        st.success(f"üé≠ G√©nero detectado: **{cat}**")
                        st.markdown(resultado)
                        
                except Exception as e:
                    st.error(f"Error al procesar el audio: {e}")
                finally:
                    # Limpieza: eliminar el archivo temporal del servidor
                    if os.path.exists(tmp_audio_path):
                        os.remove(tmp_audio_path)

st.markdown("---")
st.caption("Desarrollado con ‚ù§Ô∏è usando Streamlit, Scikit-Learn, Whisper, EasyOCR y Gemini API")